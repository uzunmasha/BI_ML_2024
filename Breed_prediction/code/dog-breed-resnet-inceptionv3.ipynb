{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:23.344782Z",
     "iopub.status.busy": "2024-04-23T06:32:23.3441Z",
     "iopub.status.idle": "2024-04-23T06:32:23.350421Z",
     "shell.execute_reply": "2024-04-23T06:32:23.349567Z",
     "shell.execute_reply.started": "2024-04-23T06:32:23.344753Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualization\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "\n",
    "import torch as T\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:25.270018Z",
     "iopub.status.busy": "2024-04-23T06:32:25.269634Z",
     "iopub.status.idle": "2024-04-23T06:32:25.298727Z",
     "shell.execute_reply": "2024-04-23T06:32:25.297534Z",
     "shell.execute_reply.started": "2024-04-23T06:32:25.269981Z"
    }
   },
   "outputs": [],
   "source": [
    "device = T.device('cuda' if T.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:25.639791Z",
     "iopub.status.busy": "2024-04-23T06:32:25.638726Z",
     "iopub.status.idle": "2024-04-23T06:32:25.693517Z",
     "shell.execute_reply": "2024-04-23T06:32:25.692608Z",
     "shell.execute_reply.started": "2024-04-23T06:32:25.639748Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read csv file\n",
    "train_data = pd.read_csv(\"/kaggle/input/dog-breed-identification/labels.csv\")\n",
    "# Train data shape\n",
    "print(f\"Train dataset shape: {train_data.shape}\")\n",
    "# Sample of the train_data DataFrame\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of the breed classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:26.813702Z",
     "iopub.status.busy": "2024-04-23T06:32:26.812871Z",
     "iopub.status.idle": "2024-04-23T06:32:28.165176Z",
     "shell.execute_reply": "2024-04-23T06:32:28.164237Z",
     "shell.execute_reply.started": "2024-04-23T06:32:26.813669Z"
    }
   },
   "outputs": [],
   "source": [
    "breed_classes = train_data.breed.value_counts().reset_index()\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.barplot(breed_classes, x='breed', y='count', palette=\"flare\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Distribution of the breed classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:28.167448Z",
     "iopub.status.busy": "2024-04-23T06:32:28.167046Z",
     "iopub.status.idle": "2024-04-23T06:32:28.179679Z",
     "shell.execute_reply": "2024-04-23T06:32:28.178716Z",
     "shell.execute_reply.started": "2024-04-23T06:32:28.16742Z"
    }
   },
   "outputs": [],
   "source": [
    "breed_classes['count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the 120 dog breed classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:28.181104Z",
     "iopub.status.busy": "2024-04-23T06:32:28.180839Z",
     "iopub.status.idle": "2024-04-23T06:32:28.190489Z",
     "shell.execute_reply": "2024-04-23T06:32:28.189438Z",
     "shell.execute_reply.started": "2024-04-23T06:32:28.181082Z"
    }
   },
   "outputs": [],
   "source": [
    "breed_classes['breed'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:28.192414Z",
     "iopub.status.busy": "2024-04-23T06:32:28.192137Z",
     "iopub.status.idle": "2024-04-23T06:32:28.202853Z",
     "shell.execute_reply": "2024-04-23T06:32:28.202052Z",
     "shell.execute_reply.started": "2024-04-23T06:32:28.192392Z"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_data['breed'] = le.fit_transform(train_data.loc[:,'breed']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:28.403347Z",
     "iopub.status.busy": "2024-04-23T06:32:28.402473Z",
     "iopub.status.idle": "2024-04-23T06:32:28.407843Z",
     "shell.execute_reply": "2024-04-23T06:32:28.406809Z",
     "shell.execute_reply.started": "2024-04-23T06:32:28.403314Z"
    }
   },
   "outputs": [],
   "source": [
    "label_map = dict(zip(le.classes_, le.transform(le.classes_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:28.959816Z",
     "iopub.status.busy": "2024-04-23T06:32:28.95946Z",
     "iopub.status.idle": "2024-04-23T06:32:28.96749Z",
     "shell.execute_reply": "2024-04-23T06:32:28.966545Z",
     "shell.execute_reply.started": "2024-04-23T06:32:28.959788Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dog_Breed_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, img_base_path: str, split: str, transforms = None):        \n",
    "        self.df = df\n",
    "        self.img_base_path = img_base_path\n",
    "        self.split = split\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Path of the image\n",
    "        img_path = os.path.join(self.img_base_path + self.df.loc[index,'id'] + '.jpg')\n",
    "        # Read the image\n",
    "        img = Image.open(img_path)        \n",
    "        # Perform the transformations\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        \n",
    "        if self.split != 'test':\n",
    "            y = self.df.loc[index, 'breed']                     \n",
    "            return img, y\n",
    "        else:            \n",
    "            return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:29.733145Z",
     "iopub.status.busy": "2024-04-23T06:32:29.732441Z",
     "iopub.status.idle": "2024-04-23T06:32:29.739477Z",
     "shell.execute_reply": "2024-04-23T06:32:29.73845Z",
     "shell.execute_reply.started": "2024-04-23T06:32:29.733114Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.2),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:44.968539Z",
     "iopub.status.busy": "2024-04-23T06:32:44.967547Z",
     "iopub.status.idle": "2024-04-23T06:32:44.986766Z",
     "shell.execute_reply": "2024-04-23T06:32:44.985742Z",
     "shell.execute_reply.started": "2024-04-23T06:32:44.968503Z"
    }
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(train_data, test_size=0.2, random_state=42, stratify=train_data['breed'])\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:45.887552Z",
     "iopub.status.busy": "2024-04-23T06:32:45.886847Z",
     "iopub.status.idle": "2024-04-23T06:32:45.893514Z",
     "shell.execute_reply": "2024-04-23T06:32:45.892532Z",
     "shell.execute_reply.started": "2024-04-23T06:32:45.887519Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Dog_Breed_Dataset(\n",
    "    df=train,\n",
    "    img_base_path='/kaggle/input/dog-breed-identification/train/',\n",
    "    split='train',\n",
    "    transforms=train_transforms\n",
    ")\n",
    "validation_dataset = Dog_Breed_Dataset(\n",
    "    df=val,\n",
    "    img_base_path='/kaggle/input/dog-breed-identification/train/',\n",
    "    split='val',\n",
    "    transforms=test_transforms\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "validation_dl = DataLoader(validation_dataset, batch_size=64, shuffle=False, num_workers=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:46.897909Z",
     "iopub.status.busy": "2024-04-23T06:32:46.89731Z",
     "iopub.status.idle": "2024-04-23T06:32:46.902798Z",
     "shell.execute_reply": "2024-04-23T06:32:46.901822Z",
     "shell.execute_reply.started": "2024-04-23T06:32:46.897876Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Train data length: {len(train_dl.dataset)}, Validation data length: {len(validation_dl.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:48.165928Z",
     "iopub.status.busy": "2024-04-23T06:32:48.16524Z",
     "iopub.status.idle": "2024-04-23T06:32:48.169827Z",
     "shell.execute_reply": "2024-04-23T06:32:48.168907Z",
     "shell.execute_reply.started": "2024-04-23T06:32:48.165897Z"
    }
   },
   "outputs": [],
   "source": [
    "# def imshow(axis, inp):\n",
    "#     \"\"\"Denormalize and show\"\"\"\n",
    "#     inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "#     axis.imshow(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:32:48.399574Z",
     "iopub.status.busy": "2024-04-23T06:32:48.399293Z",
     "iopub.status.idle": "2024-04-23T06:32:48.403876Z",
     "shell.execute_reply": "2024-04-23T06:32:48.402981Z",
     "shell.execute_reply.started": "2024-04-23T06:32:48.399552Z"
    }
   },
   "outputs": [],
   "source": [
    "# from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "# img, label = next(iter(train_dataset))\n",
    "# print(img.size(), label)\n",
    "\n",
    "# fig = plt.figure(1, figsize=(16, 12))\n",
    "# grid = ImageGrid(fig, 111, nrows_ncols=(3, 4), axes_pad=0.05)    \n",
    "\n",
    "# for i in range(img.size()[0]):\n",
    "#     ax = grid[i]\n",
    "#     imshow(ax, img[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T23:07:57.566493Z",
     "iopub.status.busy": "2024-04-22T23:07:57.566146Z",
     "iopub.status.idle": "2024-04-22T23:07:57.583345Z",
     "shell.execute_reply": "2024-04-22T23:07:57.582364Z",
     "shell.execute_reply.started": "2024-04-22T23:07:57.566466Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(train_dl, val_dl, model, epochs=50):    \n",
    "    \n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    # Best validation accuracy\n",
    "    best_val_loss = 1_000_000.0    \n",
    "    # Get initial weights\n",
    "    weights = model.get_weights()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"=\"*20, \"Epoch: \", str(epoch), \"=\"*20)\n",
    "        \n",
    "        train_correct_pred = 0\n",
    "        val_correct_pred = 0\n",
    "        train_acc = 0\n",
    "        val_acc = 0\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        for x, y in train_dl:               \n",
    "            # Convert data to Tensor            \n",
    "            x = x.clone().detach().to(device).requires_grad_(True)\n",
    "            y = y.clone().detach().long().to(device)\n",
    "            # Reset gradients\n",
    "            model.optim.zero_grad()\n",
    "            # Predict\n",
    "            preds = model(x)            \n",
    "            \n",
    "            # Compute the loss            \n",
    "            loss = model.criterion(preds,y)            \n",
    "            \n",
    "            # Compute the gradients            \n",
    "            loss.backward()\n",
    "            # Update weights\n",
    "            model.optim.step()\n",
    "            # Count the correct predictions\n",
    "            preds = T.argmax(preds, dim=1)           \n",
    "            train_correct_pred += (preds.long().unsqueeze(1) == y.unsqueeze(1)).sum().item()\n",
    "            \n",
    "            train_loss += loss.item()           \n",
    "        \n",
    "        train_acc = train_correct_pred / len(train_dl.dataset)\n",
    "        \n",
    "        train_acc_history.append(train_acc)\n",
    "               \n",
    "        train_loss_history.append(train_loss)\n",
    "        \n",
    "        # Switch to evaluation mode\n",
    "        model.eval()        \n",
    "        \n",
    "        with T.no_grad():\n",
    "            for x, y in val_dl:                \n",
    "                # Convert data to Tensor                \n",
    "                x = x.clone().detach().to(device)\n",
    "                y = y.clone().detach().long().to(device)    \n",
    "                # Predict\n",
    "                preds = model(x)                \n",
    "                # Compute the loss\n",
    "                loss = model.criterion(preds,y)                                         \n",
    "                \n",
    "                val_loss += loss.item()                \n",
    "                # Count the correct predictions\n",
    "                preds = T.argmax(preds, dim=1)\n",
    "                \n",
    "                val_correct_pred += (preds.long().unsqueeze(1) == y.unsqueeze(1)).sum().item() \n",
    "                \n",
    "        model.scheduler.step()       \n",
    "        \n",
    "        val_acc = val_correct_pred / len(val_dl.dataset)\n",
    "        \n",
    "        val_acc_history.append(val_acc)\n",
    "        val_loss_history.append(val_loss)           \n",
    "        # Save the weights of the best model\n",
    "        if best_val_loss > val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            weights = model.get_weights()\n",
    "            \n",
    "        print(\"Train acc: {:.4f} | Train Loss: {:.4f} | Validation acc: {:.4f} | Validation Loss: {:.4f}\".format(train_acc, train_loss, val_acc, val_loss))\n",
    "    # Load best model\n",
    "    model.load_weights(weights)\n",
    "    \n",
    "    return [train_acc_history, train_loss_history, val_acc_history, val_loss_history], model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:33:18.344672Z",
     "iopub.status.busy": "2024-04-23T06:33:18.344002Z",
     "iopub.status.idle": "2024-04-23T06:33:18.692633Z",
     "shell.execute_reply": "2024-04-23T06:33:18.69159Z",
     "shell.execute_reply.started": "2024-04-23T06:33:18.34464Z"
    }
   },
   "outputs": [],
   "source": [
    "inception = models.inception_v3(weights='Inception_V3_Weights.DEFAULT')\n",
    "\n",
    "inception_model = nn.Sequential(\n",
    "    inception.Conv2d_1a_3x3,\n",
    "    inception.Conv2d_2a_3x3,\n",
    "    inception.Conv2d_2b_3x3,\n",
    "    inception.maxpool1,\n",
    "    inception.Conv2d_3b_1x1,\n",
    "    inception.Conv2d_4a_3x3,\n",
    "    inception.maxpool2,\n",
    "    inception.Mixed_5b,\n",
    "    inception.Mixed_5c,\n",
    "    inception.Mixed_5d,\n",
    "    inception.Mixed_6a,\n",
    "    inception.Mixed_6b,\n",
    "    inception.Mixed_6c,\n",
    "    inception.Mixed_6d,\n",
    "    inception.Mixed_6e,\n",
    "    inception.Mixed_7a,\n",
    "    inception.Mixed_7b,\n",
    "    inception.Mixed_7c,\n",
    "    inception.avgpool\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:33:22.336328Z",
     "iopub.status.busy": "2024-04-23T06:33:22.335457Z",
     "iopub.status.idle": "2024-04-23T06:33:22.83348Z",
     "shell.execute_reply": "2024-04-23T06:33:22.832482Z",
     "shell.execute_reply.started": "2024-04-23T06:33:22.336296Z"
    }
   },
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "\n",
    "resnet50_model = nn.Sequential(\n",
    "    resnet50.conv1,\n",
    "    resnet50.bn1,\n",
    "    resnet50.relu,\n",
    "    resnet50.maxpool,\n",
    "    resnet50.layer1,\n",
    "    resnet50.layer2,\n",
    "    resnet50.layer3,\n",
    "    resnet50.layer4,\n",
    "    resnet50.avgpool\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:33:23.294582Z",
     "iopub.status.busy": "2024-04-23T06:33:23.293805Z",
     "iopub.status.idle": "2024-04-23T06:33:23.301928Z",
     "shell.execute_reply": "2024-04-23T06:33:23.300834Z",
     "shell.execute_reply.started": "2024-04-23T06:33:23.294543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freeze parameters of pretrained models\n",
    "for param in resnet50_model.parameters():    \n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in inception_model.parameters():    \n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:33:26.282058Z",
     "iopub.status.busy": "2024-04-23T06:33:26.28117Z",
     "iopub.status.idle": "2024-04-23T06:33:26.295793Z",
     "shell.execute_reply": "2024-04-23T06:33:26.294761Z",
     "shell.execute_reply.started": "2024-04-23T06:33:26.282022Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freeze training for all \"features\" layers\n",
    "for param_res, param_inc in zip(resnet50.parameters(), inception.parameters()):\n",
    "    param_res.requires_grad, param_inc.requires_grad = False, False\n",
    "    \n",
    "# replace the last fully connected layer with a Linnear layer 133 output\n",
    "in_features_resnet50 = resnet50.fc.in_features\n",
    "in_features_inception = inception.fc.in_features\n",
    "\n",
    "resnet50.fc = nn.Linear(in_features_resnet50, 120)\n",
    "inception.fc = nn.Linear(in_features_inception, 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T23:44:58.683229Z",
     "iopub.status.busy": "2024-04-22T23:44:58.682839Z",
     "iopub.status.idle": "2024-04-22T23:44:58.693489Z",
     "shell.execute_reply": "2024-04-22T23:44:58.692394Z",
     "shell.execute_reply.started": "2024-04-22T23:44:58.683202Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, inception_model, resnet50_model):\n",
    "        super(Model,self).__init__()\n",
    "        \n",
    "        self.inception_model = inception_model\n",
    "        self.resnet50_model = resnet50_model        \n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Dropout(0.7),\n",
    "            nn.Linear(4096,120)            \n",
    "        )\n",
    "        \n",
    "        self.to(device)\n",
    "        # Optimizer \n",
    "        self.optim = T.optim.SGD(self.output.parameters(), lr=0.005, momentum=0.9)\n",
    "        # Loss\n",
    "        self.criterion = T.nn.CrossEntropyLoss()\n",
    "        # Scheduler\n",
    "        self.scheduler = T.optim.lr_scheduler.StepLR(self.optim, step_size=7, gamma=0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        X1 = self.inception_model(x)\n",
    "        X2 = self.resnet50_model(x)\n",
    "        \n",
    "        X1 = X1.view(X1.size(0), -1)\n",
    "        X2 = X2.view(X2.size(0), -1)\n",
    "       \n",
    "        X = T.cat([X1, X2], dim=1)\n",
    "        \n",
    "        P = self.output(X)        \n",
    "        \n",
    "        return P\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.output.state_dict()\n",
    "    \n",
    "    def load_weights(self, weights):\n",
    "        self.output.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T23:45:03.178442Z",
     "iopub.status.busy": "2024-04-22T23:45:03.177822Z",
     "iopub.status.idle": "2024-04-22T23:45:03.199074Z",
     "shell.execute_reply": "2024-04-22T23:45:03.198158Z",
     "shell.execute_reply.started": "2024-04-22T23:45:03.17841Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(inception_model, resnet50_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T23:17:24.31852Z",
     "iopub.status.busy": "2024-04-22T23:17:24.318062Z",
     "iopub.status.idle": "2024-04-22T23:39:56.236224Z",
     "shell.execute_reply": "2024-04-22T23:39:56.234962Z",
     "shell.execute_reply.started": "2024-04-22T23:17:24.318483Z"
    }
   },
   "outputs": [],
   "source": [
    "history, model = train_model(train_dl, validation_dl, model)\n",
    "T.save(model, 'resnet-inception-sgd.pt')\n",
    "T.save(model.state_dict(), 'resnet-inception-sgd-weights.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:33:37.924969Z",
     "iopub.status.busy": "2024-04-23T06:33:37.924294Z",
     "iopub.status.idle": "2024-04-23T06:33:37.933664Z",
     "shell.execute_reply": "2024-04-23T06:33:37.932725Z",
     "shell.execute_reply.started": "2024-04-23T06:33:37.924941Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, inception_model, resnet50_model):\n",
    "        super(Model,self).__init__()\n",
    "        \n",
    "        self.inception_model = inception_model\n",
    "        self.resnet50_model = resnet50_model        \n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,120)            \n",
    "        )\n",
    "        \n",
    "        self.to(device)\n",
    "        # Optimizer \n",
    "        self.optim = T.optim.AdamW(self.output.parameters(), lr=0.005)\n",
    "        # Loss\n",
    "        self.criterion = T.nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        X1 = self.inception_model(x)\n",
    "        X2 = self.resnet50_model(x)\n",
    "        \n",
    "        X1 = X1.view(X1.size(0), -1)\n",
    "        X2 = X2.view(X2.size(0), -1)\n",
    "       \n",
    "        X = T.cat([X1, X2], dim=1)\n",
    "        \n",
    "        P = self.output(X)        \n",
    "        \n",
    "        return P\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.output.state_dict()\n",
    "    \n",
    "    def load_weights(self, weights):\n",
    "        self.output.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:33:48.162948Z",
     "iopub.status.busy": "2024-04-23T06:33:48.162196Z",
     "iopub.status.idle": "2024-04-23T06:33:48.178035Z",
     "shell.execute_reply": "2024-04-23T06:33:48.17707Z",
     "shell.execute_reply.started": "2024-04-23T06:33:48.162918Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(train_dl, val_dl, model, epochs=50):    \n",
    "    \n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    # Best validation accuracy\n",
    "    best_val_loss = 1_000_000.0    \n",
    "    # Get initial weights\n",
    "    weights = model.get_weights()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"=\"*20, \"Epoch: \", str(epoch), \"=\"*20)\n",
    "        \n",
    "        train_correct_pred = 0\n",
    "        val_correct_pred = 0\n",
    "        train_acc = 0\n",
    "        val_acc = 0\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        \n",
    "        for x, y in train_dl:               \n",
    "            # Convert data to Tensor            \n",
    "            x = x.clone().detach().to(device).requires_grad_(True)\n",
    "            y = y.clone().detach().long().to(device)\n",
    "            # Reset gradients\n",
    "            model.optim.zero_grad()\n",
    "            # Predict\n",
    "            preds = model(x)            \n",
    "            \n",
    "            # Compute the loss            \n",
    "            loss = model.criterion(preds,y)            \n",
    "            \n",
    "            # Compute the gradients            \n",
    "            loss.backward()\n",
    "            # Update weights\n",
    "            model.optim.step()\n",
    "            # Count the correct predictions\n",
    "            preds = T.argmax(preds, dim=1)           \n",
    "            train_correct_pred += (preds.long().unsqueeze(1) == y.unsqueeze(1)).sum().item()\n",
    "            \n",
    "            train_loss += loss.item()           \n",
    "        \n",
    "        train_acc = train_correct_pred / len(train_dl.dataset)\n",
    "        \n",
    "        train_acc_history.append(train_acc)\n",
    "               \n",
    "        train_loss_history.append(train_loss)\n",
    "        \n",
    "        # Switch to evaluation mode\n",
    "        model.eval()        \n",
    "        \n",
    "        with T.no_grad():\n",
    "            for x, y in val_dl:                \n",
    "                # Convert data to Tensor                \n",
    "                x = x.clone().detach().to(device)\n",
    "                y = y.clone().detach().long().to(device)    \n",
    "                # Predict\n",
    "                preds = model(x)                \n",
    "                # Compute the loss\n",
    "                loss = model.criterion(preds,y)                                         \n",
    "                \n",
    "                val_loss += loss.item()                \n",
    "                # Count the correct predictions\n",
    "                preds = T.argmax(preds, dim=1)\n",
    "                \n",
    "                val_correct_pred += (preds.long().unsqueeze(1) == y.unsqueeze(1)).sum().item() \n",
    "                   \n",
    "        \n",
    "        val_acc = val_correct_pred / len(val_dl.dataset)\n",
    "        \n",
    "        val_acc_history.append(val_acc)\n",
    "        val_loss_history.append(val_loss)           \n",
    "        # Save the weights of the best model\n",
    "        if best_val_loss > val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            weights = model.get_weights()\n",
    "            \n",
    "        print(\"Train acc: {:.4f} | Train Loss: {:.4f} | Validation acc: {:.4f} | Validation Loss: {:.4f}\".format(train_acc, train_loss, val_acc, val_loss))\n",
    "    # Load best model\n",
    "    model.load_weights(weights)\n",
    "    \n",
    "    return [train_acc_history, train_loss_history, val_acc_history, val_loss_history], model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:33:48.694353Z",
     "iopub.status.busy": "2024-04-23T06:33:48.693627Z",
     "iopub.status.idle": "2024-04-23T06:33:48.931754Z",
     "shell.execute_reply": "2024-04-23T06:33:48.930939Z",
     "shell.execute_reply.started": "2024-04-23T06:33:48.694322Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(inception_model, resnet50_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T06:33:50.387932Z",
     "iopub.status.busy": "2024-04-23T06:33:50.387302Z",
     "iopub.status.idle": "2024-04-23T06:36:05.349961Z",
     "shell.execute_reply": "2024-04-23T06:36:05.348814Z",
     "shell.execute_reply.started": "2024-04-23T06:33:50.387896Z"
    }
   },
   "outputs": [],
   "source": [
    "history, model = train_model(train_dl, validation_dl, model)\n",
    "T.save(model, 'resnet-inception-adamw.pt')\n",
    "T.save(model.state_dict(), 'resnet-inception-adamw-weights.pt')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 861871,
     "sourceId": 7327,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
